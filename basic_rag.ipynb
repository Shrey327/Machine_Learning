{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZw+Tc6znrPN987JwRtSd6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shrey327/Machine_Learning/blob/main/basic_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qI7PVrZzIsyI"
      },
      "outputs": [],
      "source": [
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYhRSu1QJP0C",
        "outputId": "90a89890-504f-44a0-dde2-f82da242d187"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.52 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.59)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.4)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"gemini-2.5-flash-preview-04-17\", model_provider=\"google_genai\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q2aW-sJIyRr",
        "outputId": "52e0cd2f-5df4-40b8-ece1-3990bc32bdab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for Google Gemini: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-huggingface"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9YK7kpNgPx7K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XQrteDuqI1na",
        "outputId": "49b0953c-7847-4af7-8a04-0d3d139dc937"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VNkasIkJI4vl",
        "outputId": "939aa9ea-60f2-4321-bf41-c8f352c2fc7b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.5.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.59)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "loader = PyPDFDirectoryLoader(\n",
        "    path = \"/content\",\n",
        "    glob = \"**/[!.]*.pdf\",\n",
        "    silent_errors = True,\n",
        "    load_hidden = False,\n",
        "    recursive = False,\n",
        "    extract_images = False,\n",
        "    password = None,\n",
        "    mode = \"page\",\n",
        "    headers = None,\n",
        "    extraction_mode = \"plain\",\n",
        ")"
      ],
      "metadata": {
        "id": "EwRm8kKlJ_wC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DuLsaBwfKMSY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain_experimental langchain_openai"
      ],
      "metadata": {
        "id": "zY1sldrEKOco"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_content = [doc.page_content for doc in docs]"
      ],
      "metadata": {
        "id": "-9FkrpCOKVmd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMbSdPW1KZl5",
        "outputId": "864d13a1-e8f0-42ce-e58b-e6cd54e2297b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Gradient**\n",
        "\n",
        "In this method, the gradient of distance is used to split chunks along with the percentile method. This method is useful when chunks are highly correlated with each other or specific to a domain e.g. legal or medical. The idea is to apply anomaly detection on gradient array so that the distribution become wider and easy to identify boundaries in highly semantic data. Similar to the percentile method, the split can be adjusted by the keyword argument breakpoint_threshold_amount which expects a number between 0.0 and 100.0, the default value is 95.0.\n",
        "\n",
        "source: Langchain"
      ],
      "metadata": {
        "id": "ilRta2ZZLPX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The docs_content variable, which contains the text extracted from the PDF, is being passed to the text_splitter.create_documents method, which in turn calls the embedding model. The presence of the invalid character '\\ud835' within the text causes errors\n"
      ],
      "metadata": {
        "id": "iSk_LcKPQVtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "text_splitter = SemanticChunker(\n",
        "    embeddings, breakpoint_threshold_type=\"gradient\"\n",
        ")"
      ],
      "metadata": {
        "id": "GYi5NG7sKdIc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_docs_content = []\n",
        "for content in docs_content:\n",
        "    cleaned_content = content.encode('utf-8', 'ignore').decode('utf-8')\n",
        "    cleaned_docs_content.append(cleaned_content)\n",
        "\n",
        "docs = text_splitter.create_documents(cleaned_docs_content)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuYpCx4-Mosq",
        "outputId": "dae78efb-7464-4a81-dcb6-4bd6bd273375"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shreyansh Pathak\n",
            "/githubgithub.com/Shrey327 /linkedinlinkedin.com/in/Shreyansh Pathak /envel⌢peshreyansh.pathak27@gmail.com\n",
            "Education\n",
            "Dayananda Sagar College Of Engineering Jun. 2027\n",
            "B.E AIML Current GPA: 8.67\n",
            "Satyam INTL School (C.B.S.E) Jun. 2022\n",
            "87.5%\n",
            "Coursework\n",
            "Courses: Object-Oriented Programming, Data Structures & Algorithms, Embedded Systems, Discrete Math,\n",
            "Linear Algebra, Calculus, Physics, Probability & Statistics, Operating Systems, Database Management\n",
            "Systems, Computer Networks, Machine Learning, Deep Learning, Natural Language Processing, Web\n",
            "Development\n",
            "Skills\n",
            "Languages: C/C++, Python, Java, JavaScript/TypeScript, HTML/CSS\n",
            "Tools: Git/GitHub, Google Colab, VS Code\n",
            "Frameworks: React, Material-UI, FastAPI, TailwindCSS\n",
            "Libraries: pandas, NumPy, Matplotlib, TensorFlow, PyTorch\n",
            "Projects\n",
            "3RVision | Python, TensorFlow, Flask, Google Colab, Git Apr. 2025\n",
            "• Built and trained a ResNet50-based computer vision model to classify product materials for sustainable lifecycle\n",
            "analysis. • Implemented data augmentation, fine-tuning, and regularization to enhance model performance across diverse\n",
            "categories. • Integrated the model into a Flask API to provide real-time reuse, recycle, and resale recommendations from\n",
            "product images. Character-Level Transformer from Scratch | PyTorch, Python, NLP Apr. 2025\n",
            "• Implemented a GPT-style character-level Transformer using PyTorch, trained on Shakespeare’s text corpus. • Built custom self-attention, multi-head attention, and feedforward layers, incorporating residual connections and\n",
            "layer normalization. • Trained the model over 5000 steps using the Adam optimizer, reducing validation loss from 4.4 to 1.82. • Gained in-depth understanding of attention mechanisms, Transformer architecture, and training dynamics in NLP\n",
            "models. High-Energy Gamma-Ray Event Classification | Python, TensorFlow, Keras, Scikit-learn Dec. 2024\n",
            "• Analyzed 19,020 simulated events from Cherenkov telescope data with 10 input features. • Developed a neural network with two hidden layers (16, 32, or 64 neurons, ReLU) and a sigmoid output for binary\n",
            "classification. • Optimized hyperparameters including node count, dropout (0, 0.2), learning rate (0.1, 0.005, 0.001), and batch size\n",
            "(32, 64, 128). • Achieved 87% accuracy and an F1-score of 0.91 for gamma particle classification.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-qdrant"
      ],
      "metadata": {
        "id": "wGKhLnvgLGDV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community"
      ],
      "metadata": {
        "id": "BLf1u1jJMMjp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7lXxon5WzdW",
        "outputId": "216bc338-fbc1-4799-d3d3-a20dac8a110a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embeddings,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")"
      ],
      "metadata": {
        "id": "_Whu-ExeMOPp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_ids = vector_store.add_documents(documents=docs)"
      ],
      "metadata": {
        "id": "pYAyhoykMw3C"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain import hub\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "\n",
        "results=rag_chain.invoke(\"briefly explain in why Shreyansh should be hired for machine learning internship\")\n",
        "display(Markdown(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "S3uH8e45RBIB",
        "outputId": "567e6011-b90c-4c2a-d443-0f12cf17fc6d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the context, Shreyansh should be hired due to his strong academic background in AIML with relevant coursework and a high GPA. He possesses practical skills in key ML tools like Python, TensorFlow, and PyTorch, demonstrated through significant projects in computer vision, NLP, and classification. These projects showcase his ability to apply machine learning techniques hands-on."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mem0ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr3jt_jRXMVv",
        "outputId": "4b484cab-f57f-446c-d781-59be9a3a606c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mem0ai in /usr/local/lib/python3.11/dist-packages (0.1.100)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from mem0ai) (1.78.1)\n",
            "Requirement already satisfied: posthog<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from mem0ai) (3.25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from mem0ai) (2.11.4)\n",
            "Requirement already satisfied: pytz<2025.0,>=2024.1 in /usr/local/lib/python3.11/dist-packages (from mem0ai) (2024.2)\n",
            "Requirement already satisfied: qdrant-client<2.0.0,>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from mem0ai) (1.14.2)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.31 in /usr/local/lib/python3.11/dist-packages (from mem0ai) (2.0.40)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.33.0->mem0ai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.33.0->mem0ai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.33.0->mem0ai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.33.0->mem0ai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.33.0->mem0ai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.33.0->mem0ai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.33.0->mem0ai) (4.13.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (1.17.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.11/dist-packages (from posthog<4.0.0,>=3.5.0->mem0ai) (2.9.0.post0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.3->mem0ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.3->mem0ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.3->mem0ai) (0.4.0)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (1.71.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (2.0.2)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (2.10.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (5.29.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client<2.0.0,>=1.9.1->mem0ai) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0.31->mem0ai) (3.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.33.0->mem0ai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.33.0->mem0ai) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai) (4.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.7->posthog<4.0.0,>=3.5.0->mem0ai) (3.4.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai) (4.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from mem0 import MemoryClient\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "kyoNJhs0YB8K"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.environ.get(\"MEM0_API_KEY\"):\n",
        "  os.environ[\"MEM0_API_KEY\"] = getpass.getpass(\"Enter API key for mem0: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqBtYBaIYVJ4",
        "outputId": "f5460708-b413-408b-c760-8ae9be918326"
      },
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for mem0: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mem0 = MemoryClient()"
      ],
      "metadata": {
        "id": "SNvPfKe3YeZ4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessage(content=\"\"\"tou are a helpful assistant with access to a knowledge base. Your task is to answer user questions accurately based on the retrieved context provided to you.\n",
        "Instructions:\n",
        "\n",
        "Always respond based on the retrieved context when it's relevant to the query.\n",
        "If the context doesn't contain the information needed to answer the question, clearly state that you don't have that specific information.\n",
        "Do not make up or infer information that isn't supported by the context.\n",
        "Keep responses concise and focused on addressing the user's question.\n",
        "When quoting directly from the context, use quotation marks.\n",
        "Always cite the specific document/source when providing information from the context.\n",
        "\n",
        "Retrieved Context:\n",
        "{{CONTEXT}}\n",
        "User Query:\n",
        "{{QUERY}}\n",
        "Response:\"\"\"+results),\n",
        "    MessagesPlaceholder(variable_name=\"context\"),\n",
        "    HumanMessage(content=\"{input}\")\n",
        "])"
      ],
      "metadata": {
        "id": "IhTm3NjpZN-6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5dD-bTNZQus"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_turn(user_input: str, user_id: str) -> str:\n",
        "    # Retrieve context\n",
        "    context = retrieve_context(user_input, user_id)\n",
        "\n",
        "    # Generate response\n",
        "    response = generate_response(user_input, context)\n",
        "\n",
        "    # Save interaction\n",
        "    save_interaction(user_id, user_input, response)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "eXMNRbaIaBEw"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context(query: str, user_id: str) -> List[Dict]:\n",
        "    \"\"\"Retrieve relevant context from Mem0\"\"\"\n",
        "    memories = mem0.search(query, user_id=user_id)\n",
        "    seralized_memories = ' '.join([mem[\"memory\"] for mem in memories])\n",
        "    context = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"Relevant information: {seralized_memories}\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": query\n",
        "        }\n",
        "    ]\n",
        "    return context\n",
        "\n",
        "def generate_response(input: str, context: List[Dict]) -> str:\n",
        "    \"\"\"Generate a response using the language model\"\"\"\n",
        "    chain = prompt | llm\n",
        "    response = chain.invoke({\n",
        "        \"context\": context,\n",
        "        \"input\": input\n",
        "    })\n",
        "    return response.content\n",
        "\n",
        "def save_interaction(user_id: str, user_input: str, assistant_response: str):\n",
        "    \"\"\"Save the interaction to Mem0\"\"\"\n",
        "    interaction = [\n",
        "        {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": user_input\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": assistant_response\n",
        "        }\n",
        "    ]\n",
        "    mem0.add(interaction, user_id=user_id)"
      ],
      "metadata": {
        "id": "yR7-Q4X_bwv8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    user_id = \"Shreyansh\"\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in ['quit', 'exit', 'bye']:\n",
        "            print(\"Agent: Thank you\")\n",
        "            break\n",
        "\n",
        "        response = chat_turn(user_input, user_id)\n",
        "        print(f\"Agent: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WELcrvpIaDGB",
        "outputId": "7380b51b-4c2f-42c4-aba0-da8be015baf4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: tell me about shreyansh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mem0/client/main.py:34: DeprecationWarning: output_format='v1.0' is deprecated therefore setting it to 'v1.1' by default.Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent: Based on the provided context, Shreyansh Pathak is a student pursuing a B.E. in AIML at Dayananda Sagar College Of Engineering. He has a strong academic background with relevant coursework and a high GPA in AIML. Shreyansh possesses practical skills in key ML tools like Python, TensorFlow, and PyTorch, and is proficient with various tools and frameworks. He also has skills in Java and JavaScript. He has demonstrated his skills through significant projects in computer vision, natural language processing, classification, and data analysis. Additionally, Shreyansh has experience as a team leader in a technical club.\n",
            "You: tell me about his skills in ml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mem0/client/main.py:34: DeprecationWarning: output_format='v1.0' is deprecated therefore setting it to 'v1.1' by default.Check out the docs for more information: https://docs.mem0.ai/platform/quickstart#4-1-create-memories\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent: Based on the context, Shreyansh's skills in ML include:\n",
            "\n",
            "*   A strong academic background in AIML (Artificial Intelligence and Machine Learning).\n",
            "*   Practical skills in key ML tools such as Python, TensorFlow, and PyTorch.\n",
            "*   Proficiency with various tools and frameworks (relevant to ML).\n",
            "*   Demonstrated ability to apply machine learning techniques hands-on through significant projects in areas like computer vision, natural language processing (NLP), and classification/data analysis.\n",
            "You: exit\n",
            "Agent: Thank you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SNa9K5CvaPZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}